####**********************************************************************
####**********************************************************************
####
####  BOOSTED MULTIVARIATE TREES FOR LONGITUDINAL DATA (BOOSTMTREE)
####  Version 1.5.0 (_PROJECT_BUILD_ID_)
####
####  Copyright 2016, University of Miami
####
####  This program is free software; you can redistribute it and/or
####  modify it under the terms of the GNU General Public License
####  as published by the Free Software Foundation; either version 3
####  of the License, or (at your option) any later version.
####
####  This program is distributed in the hope that it will be useful,
####  but WITHOUT ANY WARRANTY; without even the implied warranty of
####  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
####  GNU General Public License for more details.
####
####  You should have received a copy of the GNU General Public
####  License along with this program; if not, write to the Free
####  Software Foundation, Inc., 51 Franklin Street, Fifth Floor,
####  Boston, MA  02110-1301, USA.
####
####  ----------------------------------------------------------------
####  Project Partially Funded By:
####  ----------------------------------------------------------------
####  Dr. Ishwaran's work was funded in part by grant R01 CA163739 from
####  the National Cancer Institute.
####
####  Dr. Kogalur's work was funded in part by grant R01 CA163739 from 
####  the National Cancer Institute.
####  ----------------------------------------------------------------
####  Written by:
####  ----------------------------------------------------------------
####    Hemant Ishwaran, Ph.D.
####    Professor, Division of Biostatistics
####    Clinical Research Building, Room 1058
####    1120 NW 14th Street
####    University of Miami, Miami FL 33136
####
####    email:  hemant.ishwaran@gmail.com
####    URL:    http://web.ccs.miami.edu/~hishwaran
####    --------------------------------------------------------------
####    Amol Pande, Ph.D.
####    Assistant Staff,
####    Thoracic and Cardiovascular Surgery
####    Heart and Vascular Institute
####    JJ4, Room 508B,
####    9500 Euclid Ave,
####    Cleveland Clinic, Cleveland, Ohio, 44195
####
####    email:  amoljpande@gmail.com
####    --------------------------------------------------------------
####    Udaya B. Kogalur, Ph.D.
####    Kogalur & Company, Inc.
####    5425 Nestleway Drive, Suite L1
####    Clemmons, NC 27012
####
####    email:  ubk@kogalur.com
####    URL:    http://www.kogalur.com
####    --------------------------------------------------------------
####
####**********************************************************************
####**********************************************************************


generic.predict.boostmtree <- function(object,
                                       x,
                                       tm,
                                       id,
                                       y,
                                       M,
                                       eps = 1e-5,
                                       useCVflag = FALSE,
                                       ...)
{
  if (missing(object)) {
    stop("object is missing!")
  }
  if (sum(inherits(object, c("boostmtree", "grow"), TRUE) == c(1, 2)) != 2) {
    stop("this function only works for objects of class `(boostmtree, grow)'")
  }
  user.option <- match.call(expand.dots = TRUE)
  partial <- is.hidden.partial(user.option)
  if (!partial) {
    if (missing(x)) {
      X <- object$x
      n <- nrow(X)
      X.tm <- object$X.tm
      tm <- object$time
      tm.unq <- sort(unique(unlist(object$time)))
      id <- object$id
      id.unq <- sort(unique(id))
      testFlag <- FALSE
    }
    else {
      if (!missing(x) && (missing(id) || missing(tm))) {
        X <- x
        n <- nrow(X)
        tm.unq <- sort(unique(unlist(object$time)))
        tm <- lapply(1:n, function(i){tm.unq})
        id <- id.unq <- 1:n
        if (!missing(y)) {
          Y <- lapply(1:n, function(i) {y[i]})
          testFlag <- TRUE
        }
        else {
          testFlag <- FALSE
        }
      }
      else{
        if (missing(id)) {
          stop("test set id values are missing\n")
        }
        id.unq <- sort(unique(id))
        n <- length(id.unq)
        if (missing(x)) {
          stop("test set x values are missing\n")
        }
        X <- do.call(rbind, lapply(1:n, function(i) {
          x[id == id.unq[i],, drop = FALSE][1,, drop = FALSE]}))
        if (missing(tm)) {
          stop("test set time values are missing\n")
        }
        tm.unq <- sort(unique(tm))
        if (!missing(y)) {
          tm <- lapply(1:n, function(i) {tm[id == id.unq[i]]})
          testFlag <- TRUE
        }
        else {
          testFlag <- FALSE
        }
      }
    }
  }
  else {
      X <- x
      n <- nrow(X)
      tm.unq <- tm
      tm <- lapply(1:n, function(i){tm.unq})
      id.unq <- 1:n
      id <- rep(id.unq,each = length(tm.unq))
      testFlag <- FALSE
  }
  if (missing(M)) {
    M <- object$M
    Mflag <- FALSE
  }
  else {
    M <- max(1, min(M, object$M))
    Mflag <- TRUE
  }
  K <- object$K
  nu <- object$nu
  ntree <- object$ntree
  p <- ncol(X)
  X.tm <- object$X.tm
  df.D <- ncol(X.tm)
  xvar.names <- colnames(X)
  nu.vec <- c(nu[1], rep(nu[2], df.D - 1))
  Ymean <- object$ymean
  Ysd <- object$ysd
  baselearner <- object$baselearner
  family <- object$family
  n.Q <- object$n.Q
  Q_set <- object$Q_set
  y.unq <- object$y.unq
  na.action <- object$na.action
  #----------------------------------------------------------------------------------
  # Date: 09/04/2020
  # Following comment added as a part of estimating partial predicted mu based on
  # oob sample
  # Earlier, we use gamma estimate which is derived from all the samples, and use
  # all the training sample for prediction. Here, we focus on estimating response
  # based on the oob sample. 
  # This should be ideally be used for the partial plot, however, in case you need
  # to use gamma estimate based on oob sample, you could do that. In either case,
  # this is done using useCVflag = TRUE
  #----------------------------------------------------------------------------------
  if(useCVflag){
    if(!object$cv.flag){
      useCVflag <- FALSE
    }
  }
  if(!useCVflag){
    gamma <- object$gamma
  }else
  {
    gamma <- object$gamma.i.list
    oob.list <- lapply(1:n.Q,function(q){  vector("list",M[q]) })
  }
    if(any(is.na(X))){
    RemoveMiss.Obj <- RemoveMiss.Fun(X)
    X <- RemoveMiss.Obj$X
    id_all_na <- RemoveMiss.Obj$id.remove
    id_any_na <- which(unlist(lapply(1:nrow(X),function(i){ any(is.na(X[i,])) } )))
    if(na.action == "na.omit"){
      id_na <- id_any_na
    } else
    {
      id_na <- id_all_na
    }
    if( length(id_na) > 0 ){
      id.remove <- id.unq[id_na]
      id.unq.revise <- setdiff(id.unq,id.remove)
      index.id_revise <- match(id.unq.revise,id.unq)
      id.unq <- id.unq.revise
      n <- length(id.unq)
      tm <- lapply(index.id_revise,function(i){ tm[[i]]  })
      X <- X[index.id_revise,drop = FALSE]
      id <- unlist(lapply(1:n,function(i){ id[id == id.unq[i] ]    }))
      if(testFlag){
         y <- unlist(lapply(1:n,function(i){ y[id == id.unq[i] ]    }))
      }
    }
  }
  id.index <- lapply(1:n,function(i){
    which(id == id.unq[i] )
  })
  ni <- unlist(lapply(1:n,function(i){
    length(id.index[[i]])
  }))
  tm.unq_train <- object$tm.unq
  tm.index <- lapply(1:n,function(i){
    AppoxMatch(unlist(tm)[id.index[[i]]],tm.unq_train)
  })
  D <- lapply(1:n,function(i){
    X.tm[tm.index[[i]] ,,drop = FALSE]
  })
  beta <- matrix(0, n, df.D)
  l_pred_db.list <- lapply(1:n.Q,function(q){
    lapply(1:M,function(m){
      lapply(1:n,function(i){
        rep(0,ni[i])
      })
    })
  })
  l_pred_ref <- vector("list", M)
  Mopt <- rep(NA,n.Q)
  rmse <- rep(NA,n.Q)
  forest.tol <- object$forest.tol
  membership <- lapply(1:n.Q,function(q){
    lapply(1:M,function(m){
      NULL
    })
  })
  if(testFlag){
    if(family != "Continuous"){
      if(!is.numeric(y)){
      y <- as.numeric(factor(y))
     }
      y.unq_test <- sort(unique(y))
      if(any(is.na(match(y.unq_test,y.unq)))){
        stop("Unique values of response from training and test data do not match")
      }
    }
    Yq <- lapply(1:n.Q,function(q){
      if(family == "Continuous"){
        out <- y
      }
      if(family == "Nominal" || family == "Binary"){
        out <- ifelse(y == Q_set[q],1,0)
      }
      if(family == "Ordinal"){
        out <- ifelse(y <= Q_set[q],1,0)
      }
      out
    })
    Y <- lapply(1:n.Q,function(q){
      lapply(1:n, function(i) { Yq[[q]][id == id.unq[i]] })
    })
  }
  if (ntree == 1) {
    rf.cores.old <- getOption("rf.cores")
    mc.cores.old <- getOption("mc.cores")
    for(q in 1:n.Q){
      nullObj <- papply(1:M, function(m) {
        options(rf.cores = 1, mc.cores = 1)
        if(!useCVflag){
        membership[[q]][[m]] <<- c(predict.rfsrc(baselearner[[q]][[m]],
                                                 newdata = X,
                                                 membership = TRUE,
                                                 ptn.count = K,
                                                 na.action = na.action,
                                                 importance = "none")$ptn.membership)
        } else
        {
          oob <- which(baselearner[[q]][[m]]$inbag == 0)
          oob.list[[q]][[m]] <<- oob
          membership[[q]][[m]] <<- c(predict.rfsrc(baselearner[[q]][[m]],
                                                   newdata = X[oob,, drop = FALSE],
                                                   membership = TRUE,
                                                   ptn.count = K,
                                                   na.action = na.action,
                                                   importance = "none")$ptn.membership)
        }
        NULL
      })
      rm(nullObj)
    }
    for(q in 1:n.Q){
      nullObj <- lapply(1:M, function(m) {
        if(!useCVflag){
        orgMembership <- gamma[[q]][[m]][, 1]
        if (m == 1) {
          l_pred_db.list[[q]][[m]] <<- lapply(1:n, function(i) {
            l_pred_db_Temp <- D[[i]]%*%t(gamma[[q]][[m]][match(membership[[q]][[m]][i], orgMembership), -1, drop = FALSE]*nu.vec) 
            if(family == "Ordinal" && q > 1){
              l_pred_db_Temp <- ifelse(l_pred_db_Temp < l_pred_db.list[[q-1]][[m]][[i]],l_pred_db.list[[q-1]][[m]][[i]],l_pred_db_Temp)
            }
            l_pred_db_Temp
            })
        }
        else {
          l_pred_db.list[[q]][[m]] <<- lapply(1:n, function(i) {
            l_pred_db_Temp <- unlist(l_pred_db.list[[q]][[m-1]][i]) + D[[i]]%*%t(gamma[[q]][[m]][match(membership[[q]][[m]][i], orgMembership), -1, drop = FALSE]*nu.vec)
            if(family == "Ordinal" && q > 1){
              l_pred_db_Temp <- ifelse(l_pred_db_Temp < l_pred_db.list[[q-1]][[m]][[i]],l_pred_db.list[[q-1]][[m]][[i]],l_pred_db_Temp)
            }
            l_pred_db_Temp
          })
        }
       } else
       {
         if(m == 1){
           l_pred_db.list[[q]][[m]] <<- lapply(1:n,function(i){
             if( any(i == oob.list[[q]][[m]] )){
               orgMembership <- gamma[[q]][[m]][[i]][,1,drop = TRUE]
               l_pred_db_Temp <- D[[i]]%*%t(gamma[[q]][[m]][[i]][match(membership[[q]][[m]][ which(oob.list[[q]][[m]] == i) ], orgMembership), -1, drop = FALSE]*nu.vec) 
               if(family == "Ordinal" && q > 1){
                 l_pred_db_Temp <- ifelse(l_pred_db_Temp < l_pred_db.list[[q-1]][[m]][[i]],l_pred_db.list[[q-1]][[m]][[i]],l_pred_db_Temp)
               }   
             } else
             {
               l_pred_db_Temp <- l_pred_db.list[[q]][[m]][[i]]
             }
             l_pred_db_Temp
           })
         }else
         {
           l_pred_db.list[[q]][[m]] <<- lapply(1:n,function(i){
             if( any(i == oob.list[[q]][[m]] )){
               orgMembership <- gamma[[q]][[m]][[i]][,1,drop = TRUE]
               l_pred_db_Temp <- l_pred_db.list[[q]][[m-1]][[i]] + D[[i]]%*%t(gamma[[q]][[m]][[i]][match(membership[[q]][[m]][ which(oob.list[[q]][[m]] == i) ], orgMembership), -1, drop = FALSE]*nu.vec) 
               if(family == "Ordinal" && q > 1){
                 l_pred_db_Temp <- ifelse(l_pred_db_Temp < l_pred_db.list[[q-1]][[m]][[i]],l_pred_db.list[[q-1]][[m]][[i]],l_pred_db_Temp)
               }   
             } else
             {
               l_pred_db_Temp <- l_pred_db.list[[q]][[m-1]][[i]]
             }
             l_pred_db_Temp
           })
         }
       }
        NULL
      })
      rm(nullObj)
    }
    if(family == "Nominal"){
    nullObj <- lapply(1:M,function(m){
      l_pred_ref[[m]] <<- lapply(1:n,function(i){
        log((1 + (Reduce("+",lapply(1:n.Q,function(q){
          exp(l_pred_db.list[[q]][[m]][[i]])  
        }))))^{-1})
      })
      NULL
    })
    rm(nullObj)
    } else
    {
      nullObj <- lapply(1:M,function(m){
        l_pred_ref[[m]] <<- lapply(1:n,function(i){
                        rep(0,ni[i])
        })
        NULL
      })
      rm(nullObj)
    }
    l_pred.list <- lapply(1:n.Q,function(q){
      lapply(1:M,function(m){
        lapply(1:n,function(i){
          l_pred_db.list[[q]][[m]][[i]] + l_pred_ref[[m]][[i]]
        })
      })
    })
    l_pred.list <- lapply(1:n.Q,function(q){
      lapply(1:M,function(m){
        lapply(1:n,function(i){
          l_pred.list[[q]][[m]][[i]] * Ysd + Ymean
        })
      })
    })
    mu.list <- lapply(1:n.Q,function(q){
      lapply(1:M,function(m){
        lapply(1:n,function(i){
          GetMu(Linear_Predictor = l_pred.list[[q]][[m]][[i]],Family = family)
        })
      })
    })
    if (testFlag) {
      err.rate <- lapply(1:n.Q,function(q){
        err.rate_temp <- matrix(unlist(lapply(1:M, function(m) {
          c(l1Dist(Y[[q]], mu.list[[q]][[m]]), l2Dist(Y[[q]], mu.list[[q]][[m]])) 
        })), ncol = 2, byrow = TRUE)
        colnames(err.rate_temp) <- c("l1", "l2")
        err.rate_temp
      })
    }
    else {
      err.rate <- NULL
    }
    for(q in 1:n.Q){
      if (!Mflag && testFlag) {
        diff.err <- abs(err.rate[[q]][, "l2"] - min(err.rate[[q]][, "l2"], na.rm = TRUE))
        diff.err[is.na(diff.err)] <- 1
        if (sum(diff.err < Ysd * eps) > 0) {
          Mopt[q] <- min(which(diff.err < eps))
        }
        else {
          Mopt[q] <- M
        }
       rmse[q] <- err.rate[[q]][Mopt[q], "l2"]
      }
      else {
        Mopt[q] <- M
      }
    }
    mu <- lapply(1:n.Q,function(q){ mu.list[[q]][[ Mopt[q] ]]  })
    if(family == "Ordinal"){
      Prob_class <- lapply(1:(n.Q+1),function(q){
        if(q == 1){
          out <- lapply(1:n,function(i){
            mu[[q]][[i]]
          })
        }
        if(q == (n.Q+1)){
          out <- lapply(1:n,function(i){
            1 - mu[[q-1]][[i]]
          })
        }
        if(q > 1 && q < (n.Q+1) ){
          out <- lapply(1:n,function(i){
            mu[[q]][[i]] - mu[[q-1]][[i]]
          })
        }
        out
      })
    } else
    {
      Prob_class <- NULL
    }
  }
  else{
    nullObj <- lapply(1:M, function(m) {
      gm <- baselearner[[m]]$gm
      Xnew <- baselearner[[m]]$Xnew
      pen <- baselearner[[m]]$pen
      forest.wt <- predict.rfsrc(baselearner[[m]]$forest,
                                 newdata = X,
                                 importance = "none",
                                 forest.wt = TRUE)$forest.wt
      beta.m.org <- do.call("cbind", mclapply(1:n, function(i) {
        fwt.i <- forest.wt[i, ]
        fwt.i[fwt.i <= forest.tol] <- 0
        pt.i <- (fwt.i != 0)
        if (sum(pt.i) > 0) {
          fwt.i <- fwt.i / sum(fwt.i)
          YnewSum <- colSums(fwt.i[pt.i] * gm[pt.i,, drop = FALSE])
          XnewSum <- Reduce("+", lapply(which(pt.i), function(j) {fwt.i[j] * Xnew[[j]]}))
          XnewSum <- XnewSum + pen
          qr.obj <- tryCatch({qr.solve(XnewSum, YnewSum)}, error = function(ex){NULL})
          if (!is.null(qr.obj)) {
            qr.obj
          }
          else {
            rep(0, df.D)
          }
        }
        else {
          rep(0, df.D)
        }
      }))
      beta.m <- t(beta.m.org * nu.vec * Ysd)
      if (m == 1) {
        beta.m[, 1] <- beta.m[, 1] + Ymean
        beta <<- beta.m
      }
      else {
        beta <<- beta + beta.m 
      }
      Dbeta.m <- D %*% (beta.m.org * nu.vec)
      if (m == 1) {
        mu.list[[m]] <<- lapply(1:n, function(i) {
          Dbeta.m[, i][match(tm[[i]], tm.unq, tm[[i]])]
        })
      }
      else {
        mu.list[[m]] <<- lapply(1:n, function(i) {
          unlist(mu.list[[m-1]][i]) + Dbeta.m[, i][match(tm[[i]], tm.unq, tm[[i]])]
        })
      }
      NULL
    })
    mu.list <- lapply(mu.list, function(mlist){  
      lapply(1:n,function(i) {mlist[[i]] * Ysd + Ymean})
    })
    if (testFlag) {
      err.rate <- matrix(unlist(lapply(mu.list, function(mlist) {
        c(l1Dist(Y, mlist), l2Dist(Y, mlist))
      })), ncol = 2, byrow = TRUE) 
      colnames(err.rate) <- c("l1", "l2")
    }
    else {
      err.rate <- NULL
    }
    if (!Mflag && testFlag) {
      diff.err <- abs(err.rate[, "l2"] - min(err.rate[, "l2"], na.rm = TRUE))
      diff.err[is.na(diff.err)] <- 1
      if (sum(diff.err < Ysd * eps) > 0) {
        Mopt <- min(which(diff.err < eps))
      }
      else {
        Mopt <- M
      }
    }
    else {
      Mopt <- M
    }
  }
  #----------------------------------------------------------------------------------
  # Date: 09/08/2020
  # Following comment added as a part of estimating partial predicted mu based on
  # oob sample.
  # Earlier I have provided an estimate of mu based on gamma obtained using oob sample.
  # This is in addition to the mu based on gamma obtained using all the sample.
  # In the procedure below, I am going to estimate muhat and Prob_hat_class only
  # based on gamma obtained using all the sample. Thus, when useCVflag == TRUE,
  # we use muhat and Prob_hat_class as NULL.
  # This is due to time constraints.
  # Later, I will come back to the code below, and provide two separate estimates,
  # one based on gamma from all the sample, and other based on gamma from oob sample.
  #----------------------------------------------------------------------------------
  if(!useCVflag){
  l_pred_db_hat_Temp <- lapply(1:n.Q,function(q){
    lapply(1:n,function(i){
      lapply(1:Mopt[q],function(m){
        orgMembership <- gamma[[q]][[m]][, 1]
        as.vector(X.tm%*%t(gamma[[q]][[m]][match(membership[[q]][[m]][i], orgMembership), -1, drop = FALSE]*nu.vec))
      })
    })
  })
  l_pred_db_hat <- lapply(1:n.Q,function(q){
    lapply(1:n,function(i){
       sum_l_pred_db_Temp <- Reduce("+",lapply(1:Mopt[q],function(m){
        l_pred_db_Temp <- l_pred_db_hat_Temp[[q]][[i]][[m]]
        if(family == "Ordinal" && q > 1){
          l_pred_db_Temp <- ifelse(l_pred_db_Temp < l_pred_db_hat_Temp[[q-1]][[i]][[m]],l_pred_db_hat_Temp[[q-1]][[i]][[m]],l_pred_db_Temp)
          l_pred_db_hat_Temp[[q]][[i]][[m]] <<- l_pred_db_Temp
          l_pred_db_Temp
        }
        l_pred_db_Temp
      }))
       sum_l_pred_db_Temp
    })
  })
  #if(FALSE){
  # This should be deleted once I know that above code works
  #l_pred_db_hat <- lapply(1:n.Q,function(q){
  #  l_pred_db_i_list <- lapply(1:n,function(i){
  #    l_pred_db.i <- rep(0,nrow(X.tm))
  #    nullObj <- lapply(1:Mopt[q],function(m){
  #      orgMembership <- gamma[[q]][[m]][, 1]
  #      l_pred_db.i <<- l_pred_db.i + X.tm%*%t(gamma[[q]][[m]][match(membership[[q]][[m]][i], orgMembership), -1, drop = FALSE]*nu.vec)
  #      NULL
  #    })
  #    l_pred_db.i
  #  })
  #  l_pred_db_i_list
  #})
  #}
  if(family == "Nominal"){
  l_pred_ref_hat <- lapply(1:n,function(i){
      log((1 + (Reduce("+",lapply(1:n.Q,function(q){
        exp(l_pred_db_hat[[q]][[i]])  
      }))))^{-1})
  })
  } else 
  {
    l_pred_ref_hat <- lapply(1:n,function(i){
      rep(0,nrow(X.tm))
    })
  }
  l_pred_hat <- lapply(1:n.Q,function(q){
    lapply(1:n,function(i){
      (l_pred_db_hat[[q]][[i]] + l_pred_ref_hat[[i]])* Ysd + Ymean
    })
  })
  muhat <- lapply(1:n.Q,function(q){
    lapply(1:n,function(i){
      GetMu(Linear_Predictor = l_pred_hat[[q]][[i]],Family = family)
    })
  })
  if(family == "Ordinal"){
    Prob_hat_class <- lapply(1:(n.Q+1),function(q){
      if(q == 1){
        out <- lapply(1:n,function(i){
          muhat[[q]][[i]]
        })
      }
      if(q == (n.Q+1)){
        out <- lapply(1:n,function(i){
          1 - muhat[[q-1]][[i]]
        })
      }
      if(q > 1 && q < (n.Q+1) ){
        out <- lapply(1:n,function(i){
          muhat[[q]][[i]] - muhat[[q-1]][[i]]
        })
      }
      out
    })
  } else
  {
    Prob_hat_class <- NULL
  }
 }else
 {
   muhat <- NULL
   Prob_hat_class <- NULL
 }
  object$baselearner <- object$membership <- object$gamma <- NULL
  pobj <- list(boost.obj = object,
               x = X,
               time = tm,
               id = id,
               y = if (testFlag) y else NULL,
               Y = if(testFlag) {if(family == "Nominal" || family == "Ordinal") Y else unlist(Y,recursive=FALSE)} else NULL,
               family = family,
               ymean = Ymean,
               ysd = Ysd,
               xvar.names = xvar.names,
               K = K,
               n = n,
               ni = ni,
               n.Q = n.Q,
               Q_set = Q_set,
               y.unq = y.unq,
               nu.vec = nu.vec,
               D = D,
               df.D = df.D,
               time.unq = tm.unq,
               baselearner = baselearner,
               gamma = gamma,
               membership = membership,
               mu = if(family == "Nominal" || family == "Ordinal") mu else unlist(mu,recursive=FALSE),
               Prob_class = Prob_class,
               muhat = if(!useCVflag)  if(family == "Nominal" || family == "Ordinal") muhat else unlist(muhat,recursive=FALSE) else NULL,
               Prob_hat_class = Prob_hat_class,
               err.rate = if (!is.null(err.rate)) { if(family == "Nominal" || family == "Ordinal") lapply(1:n.Q,function(q){ err.rate[[q]] / Ysd   }) else err.rate[[1]]/Ysd }  else NULL,
               rmse = if (testFlag) unlist(lapply(1:n.Q,function(q) { rmse[q] / Ysd })) else NULL,
               Mopt = if (testFlag) Mopt else NULL)
  class(pobj) <- c("boostmtree", "predict", class(object)[3])
  invisible(pobj)
}
